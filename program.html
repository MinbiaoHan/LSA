<!DOCTYPE HTML>
<!--
	Verti by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<style>
		.row{
			display: flex;
		}
		
		.column {
			flex: 50.00%;
			padding: 5px;
			text-align:center;
		}
		
		.column img {
			display: block;
			margin-left: auto;
  			margin-right: auto;
			width: 205px;
			height: 300px;
			border-radius:50%;
		}
		
		.column figcaption {
			text-align: center;
		}
	</style>
	<head>
		<title>Learning with Strategic Agents Workshop</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload no-sidebar">
		<div id="page-wrapper">

			<!-- Header -->
			<div id="header-wrapper">
				<header id="header" class="container">

					<!-- Logo -->
						<div id="logo">
							<h3><a href="index.html">Learning with Strategic Agents Workshop</a></h3>
							<!--<span>by HTML5 UP</span>-->
						</div>

					<!-- Nav -->
						<nav id="nav">
							<ul>
                                <li><a href="index.html">Welcome</a></li>
                                <li><a href="CallForPaper.html">Call for Papers</a></li>
                                <li class="current"><a href="program.html">Program</a></li>
                                <li><a href="organization.html">Organization</a></li>
				<li><a href="papers.html">Accepted Papers</a></li>
                            </ul>
						</nav>

				</header>
			</div>

			<!-- Main -->
				<div id="main-wrapper">
					<div class="container">
						<div id="content">

							<!-- Content -->
								<article>
									<p> LSA will take place virtually over the course of two days. Oral sessions will be hosted on Zoom, and can be joined
										via the link below. </br>
										<b>Zoom Link:</b> The Zoom link will be available nearer the start time of the workshop. <br>
										In addition, LSA is hosting two joint poster sessions with the ALA and GAIW workshops, which are also taking place
										at AAMAS 2022. Each poster session will take place in the Gather Town space shared below: <br>
										<b>Gather Town Link: </b> https://app.gather.town/events/O8p6uZQ3G1EJELYsXH2v <br>
										Please find detailed information regarding the workshop schedule below. Please note that all times <b> and dates </b> are listed
										in Auckland time (UTC+12).
									</p>		
									
										
									<h3>Tuesday, May 10</h3>
									<table>
										<tr>
										    <th>Time (GMT+12)</th>
										    <th> Subject </th>
										    <th>Authors</th>
										    <th>Title</th>
										 </tr>
										<tr>
											<td>02:00-02:55</td>
											<td>Poster Session 1</td>
										 	<td></td>
											<td></td>
										 </tr>
										 <tr>
											<td>03:00-03:20</td>
											<td>Paper Spotlight</td>
										 	<td>Xiaotie Deng, Xinyan Hu, Tao Lin and Weiqiang Zheng</td>
									    		<td><a href="papers/LSA-2022_paper_11.pdf">Nash Convergence of Mean-Based Learning Algorithms in First Price Auctions</a></td>
										 </tr>
										<tr>
											<td>03:20-03:40</td>
											<td>Paper Spotlight</td>
										 	<td>Vineet Nair, Ganesh Ghalme, Inbal Talgam-Cohen and Nir Rosenfeld</td>
											<td><a href="papers/LSA-2022_paper_12.pdf">Strategic Representation</a></td>
										</tr>
										<tr>
											<td>03:40-04:00</td>
											<td>Paper Spotlight</td>
										 	 <td>Tal Lancewicki, Aviv Rosenberg and Yishay Mansour</td>
									    		<td><a href="papers/LSA-2022_paper_7.pdf">Cooperative Online Learning in Stochastic and Adversarial MDPs</a></td>
									  	</tr>
										<tr>
											<td>04:00-05:00</td>
											<td>Invited Talk</td>
										 	 <td>Panayotis Mertikopoulos</td>
									    		<td>Limits and Limit Points of Game-Theoretic Learning</td>
									  	</tr>
										<tr>
											<td>05:00-05:20</td>
											<td>Paper Spotlight</td>
										 	 <td>Gabriel Andrade, Rafael Frongillo and Georgios Piliouras</td>
											    <td><a href="papers/LSA-2022_paper_18.pdf">No-Regret Learning in Games is Turing Complete</a></td>
										</tr>
										<tr>
											<td>05:20-05:40</td>
											<td>Paper Spotlight</td>
										 	 <td>Martino Bernasconi, Federico Cacciamani, Simone Fioravanti, Alberto Marchesi, Nicola Gatti and Francesco Trovò</td>
										    		<td><a href="papers/LSA-2022_paper_14.pdf">Exploiting Opponents Subject to Utility Constraints in Extensive-Form Games</a></td>
										  </tr>
										<tr>
											<td>06:15-07:15</td>
											<td>Poster Session 2</td>
											<td></td>
											<td></td>
										 </tr>
									</table>
									<h3>Wednesday, May 11</h3>
									<table>
										<tr>
										    <th>Time (GMT+12)</th>
										    <th> Subject </th>
										    <th>Authors</th>
										    <th>Title</th>
										 </tr>
										<tr>
											<td>03:00-04:00</td>
											<td>Invited Talk</td>
										 	 <td>Amy Greenwald</td>
									    		<td>No-Regret Learning in Extensive-Form Games</td>
										 </tr>
										 <tr>
											<td>04:00-04:20</td>
											<td>Paper Spotlight</td>
										 	<td>Andrew Estornell, Sanmay Das, Yang Liu and Yevgeniy Vorobeychik</td>
											<td>Unfairness Despite Awareness: Group-Fair Classification with Strategic Agents</td>
									    	</tr>
										<tr>
											<td>04:20-04:40</td>
											<td>Paper Spotlight</td>
										 	<td>Keegan Harris, Valerie Chen, Joon Sik Kim, Ameet Talwalkar, Hoda Heidari and Z. Steven Wu</td>
										    	<td><a href="papers/LSA-2022_paper_5.pdf">Bayesian Persuasion for Algorithmic Recourse</a></td>
										  </tr>
										<tr>
											<td>04:40-05:00</td>
											<td>Paper Spotlight</td>
										 	<td>Tosca Lechner and Ruth Urner</td>
										    <td><a href="https://arxiv.org/abs/2203.13421">Learning Losses for Strategic Classification</a></td>
										  </tr>
										<tr>
											<td>05:00-05:20</td>
											<td>Paper Spotlight</td>
										 	 <td>Lirong Xia</td>
										    <td><a href="papers/LSA-2022_paper_3.pdf">How Likely A Coalition of Voters Can Influence A Large Election?</a></td>
										  </tr>
										<tr>
											<td>05:20-05:40</td>
											<td>Paper Spotlight</td>
										 	 <td>Fan Yao, Chuanhao Li, Denis Nekipelov, Hongning Wang and Haifeng Xu</td>
										<td><a href="papers/LSA-2022_paper_2 (1).pdf">Learning from a Learning User for Optimal Recommendations</a></td>
									    </tr>
										<tr>
											<td>05:40-06:00</td>
											<td>Paper Spotlight</td>
										 	 <td>Keegan Harris, Daniel Ngo, Logan Stapleton, Hoda Heidari and Z. Steven Wu</td>
										    <td><a href="papers/LSA-2022_paper_4.pdf">Strategic Instrumental Variable Regression: Recovering Causal Relationships From Strategic Responses</a></td>
										  </tr>
									</table>
									<h3>Invited Talks</h3>
									<div class="row">
										<div class="column">
											<figure>
												<img src="images/panayotis.png">
												<figcaption> 
													<h3> Panayotis Mertikopoulos </h3> 
												</figcaption>
											</figure>
										</div>
										<div class="column">
											<div class="center">
												<figure>
													<img src="images/amy2.png">
													<figcaption>
														<h3> Amy Greenwald </h3>
													</figcaption>
												</figure>
											</div>
										</div>
									</div>
									
									<p>
									<b>Speaker: </b> <a href="http://polaris.imag.fr/panayotis.mertikopoulos/">Panayotis Mertikopoulos</a>, French National Center for Scientific Research (CNRS) <br>
									<b>Title: </b> Limits and Limit Points of Game-Theoretic Learning <br>
									<b>Talk Abstract</b> <br>Does learning from empirical observations in a game-theoretic setting converge to a Nash equilibrium? And, if so, at what rate? A well-known impossibility result in the field precludes the possibility of a "universally positive" answer - i.e., the existence a dynamical process which, based on player-specific information alone, converges to Nash equilibrium in all games. In view of this, we will instead examine the equilibrium convergence properties of a class of widely used no-regret learning processes which includes the exponential weights algorithm and the “follow the regularized leader” family of methods, their optimistic variants, extra-gradient schemes, and many others. In this general context, we establish a comprehensive equivalence between the stability of a Nash equilibrium and its support: a Nash equilibrium is locally stable and attracting if and only if it is strict (i.e., each equilibrium strategy has a unique best response). We will also discuss the robustness of this equivalence to different feedback models - from full information to bandit, payoff-based feedback - as well as the methods' rate of convergence in terms of the underlying regularizer and the type of feedback available to the players.<br>
									<b>Speaker Bio</b><br> Panayotis Mertikopoulos is a principal researcher at the French National Center for Scientific Research (CNRS). Before joining CNRS, he received his undergraduate degree in physics from the University of Athens, his MSc and MPhil in mathematics from Brown University, and his PhD also from the University of Athens. He has since spent a year at École Polytechnique in France as a postdoctoral researcher, and has held visiting positions as an invited professor at the University of Rome, UC Berkeley, and EPFL. His research interests span the interface of game theory, learning and optimization, with a special view towards their applications to machine learning, operations research, and network theory. He is especially interested in the equilibrium convergence properties of multi-agent learning algorithms and dynamics, their rate of convergence (when they converge), and the type of off-equilibrium behavior that may arise (when they do not).
									</p>
									<p>
									<b>Speaker: </b><a href="https://cs.brown.edu/people/faculty/amy/">Amy Greenwald</a>, Brown University <br>
									<b>Title: </b> No-Regret Learning in Extensive-Form Games <br>
									<b>Talk Abstract</b> <br> The convergence of \Phi-regret-minimization algorithms in self-play to \Phi-correlated-equilibria is well understood in normal-form games (NFGs), where \Phi is the set of deviation strategies. This talk investigates the analogous relationship in extensive-form games (EFGs). While the primary choices for \Phi in NFGs are internal and external regret, the space of possible deviations in EFGs is much richer. We restrict attention to a class of deviations known as behavioral deviations, inspired by von Stengel and Forges' deviation player, which they introduced when defining behavioral correlated equilibria (BCE). We then propose extensive-form regret minimization (EFR), a regret-minimizing learning algorithm whose complexity scales with the complexity of \Phi, and which converges in self-play to BCE when \Phi is the set of behavioral deviations. Von Stengel and Forges, Zinkevich et al., and Celli et al. all weaken the deviation player in various ways, and then derive corresponding efficient equilibrium-finding algorithms. These weakenings (and others) can be seamlessly encoded into EFR at runtime, by simply defining an appropriate \Phi. The result is a class of efficient \Phi-equilibrium finding algorithms for EFGs. <br>
									<b>Speaker Bio</b><br> Amy Greenwald is Professor of Computer Science at Brown University in Providence, Rhode Island.  Her research focuses on game-theoretic and economic interactions among computational agents, applied to areas like autonomous bidding in wireless spectrum auctions and ad exchanges.  Before joining Brown, Greenwald was a postdoctoral researcher at IBM's T.J. Watson Research Center, where her "Shopbots and Pricebots" paper was named Best Paper at IBM Research.  Her honors include the Presidential Early Career Award for Scientists and Engineers (PECASE), a Fulbright nomination, and a Sloan Fellowship.  Finally, Greenwald is active in promoting diversity in Computer Science, leading multiple K-12 initiatives in which Brown undergraduates teach computer science to Providence public school students.
									</p>
									
								</article>

						</div>
					</div>
				</div>

			<!-- Footer -->
				<div id="footer-wrapper">
					<footer id="footer" class="container">
						<div class="row">
							<div class="col-12">
								<div id="copyright">
									<ul class="menu">
										<li>&copy;  AAMAS 2022. All rights reserved</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
									</ul>
								</div>
							</div>
						</div>
					</footer>
				</div>

			</div>

		<!-- Scripts -->

			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
