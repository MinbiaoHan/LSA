<!DOCTYPE HTML>
<!--
	Verti by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Learning with Strategic Agents Workshop</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload no-sidebar">
		<div id="page-wrapper">

			<!-- Header -->
			<div id="header-wrapper">
				<header id="header" class="container">

					<!-- Logo -->
						<div id="logo">
							<h3><a href="index.html">Learning with Strategic Agents Workshop</a></h3>
							<!--<span>by HTML5 UP</span>-->
						</div>

					<!-- Nav -->
						<nav id="nav">
							<ul>
                                <li><a href="index.html">Welcome</a></li>
                                <li><a href="CallForPaper.html">Call for Papers</a></li>
                                <li class="current"><a href="program.html">Program</a></li>
                                <li><a href="organization.html">Organization</a></li>
				<li><a href="papers.html">Accepted Papers</a></li>
                            </ul>
						</nav>

				</header>
			</div>

			<!-- Main -->
				<div id="main-wrapper">
					<div class="container">
						<div id="content">

							<!-- Content -->
								<article>

									<h3>Tuesday, May 10</h3>
									<table>
										<tr>
										    <th>Time(GMT+12)</th>
										    <th> Subject </th>
										    <th>Authors</th>
										    <th>Title</th>
										 </tr>
										<tr>
											<td>02:00-02:55</td>
											<td>Poster Session 1</td>
										 	<td></td>
											<td></td>
										 </tr>
										 <tr>
											<td>03:00-03:20</td>
											<td>Paper Spotlight</td>
										 	<td>Xiaotie Deng, Xinyan Hu, Tao Lin and Weiqiang Zheng</td>
									    		<td><a href="papers/LSA-2022_paper_11.pdf">Nash Convergence of Mean-Based Learning Algorithms in First Price Auctions</a></td>
										 </tr>
										<tr>
											<td>03:20-03:40</td>
											<td>Paper Spotlight</td>
										 	<td>Vineet Nair, Ganesh Ghalme, Inbal Talgam-Cohen and Nir Rosenfeld</td>
											<td><a href="papers/LSA-2022_paper_12.pdf">Strategic Representation</a></td>
										</tr>
										<tr>
											<td>03:40-04:00</td>
											<td>Paper Spotlight</td>
										 	 <td>Tal Lancewicki, Aviv Rosenberg and Yishay Mansour</td>
									    		<td><a href="papers/LSA-2022_paper_7.pdf">Cooperative Online Learning in Stochastic and Adversarial MDPs</a></td>
									  	</tr>
										<tr>
											<td>04:00-05:00</td>
											<td>Invited Talk</td>
										 	 <td>Panayotis Mertikopoulos</td>
									    		<td>Limits and Limit Points of Game-Theoretic Learning</td>
									  	</tr>
										<tr>
											<td>05:00-05:20</td>
											<td>Paper Spotlight</td>
										 	 <td>Gabriel Andrade, Rafael Frongillo and Georgios Piliouras</td>
											    <td><a href="papers/LSA-2022_paper_18.pdf">No-Regret Learning in Games is Turing Complete</a></td>
										</tr>
										<tr>
											<td>05:20-05:40</td>
											<td>Paper Spotlight</td>
										 	 <td>Martino Bernasconi, Federico Cacciamani, Simone Fioravanti, Alberto Marchesi, Nicola Gatti and Francesco Trovò</td>
										    		<td><a href="papers/LSA-2022_paper_14.pdf">Exploiting Opponents Subject to Utility Constraints in Extensive-Form Games</a></td>
										  </tr>
										<tr>
											<td>06:15-07:15</td>
											<td>Poster Session 2</td>
											<td></td>
											<td></td>
										 </tr>
									</table>
									<h3>Wednesday, May 11</h3>
									<table>
										<tr>
										    <th>Time(GMT+12)</th>
										    <th> Subject </th>
										    <th>Authors</th>
										    <th>Title</th>
										 </tr>
										<tr>
											<td>03:00-04:00</td>
											<td>Invited Talk</td>
										 	 <td>Amy Greenwald</td>
									    		<td>TBA</td>
										 </tr>
										 <tr>
											<td>04:00-04:20</td>
											<td>Paper Spotlight</td>
										 	<td>Andrew Estornell, Sanmay Das, Yang Liu and Yevgeniy Vorobeychik</td>
											<td>Unfairness Despite Awareness: Group-Fair Classification with Strategic Agents</td>
									    	</tr>
										<tr>
											<td>04:20-04:40</td>
											<td>Paper Spotlight</td>
										 	<td>Keegan Harris, Valerie Chen, Joon Sik Kim, Ameet Talwalkar, Hoda Heidari and Z. Steven Wu</td>
										    	<td><a href="papers/LSA-2022_paper_5.pdf">Bayesian Persuasion for Algorithmic Recourse</a></td>
										  </tr>
										<tr>
											<td>04:40-05:00</td>
											<td>Paper Spotlight</td>
										 	<td>Tosca Lechner and Ruth Urner</td>
										    <td><a href="https://arxiv.org/abs/2203.13421">Learning Losses for Strategic Classification</a></td>
										  </tr>
										<tr>
											<td>05:00-05:20</td>
											<td>Paper Spotlight</td>
										 	 <td>Lirong Xia</td>
										    <td><a href="papers/LSA-2022_paper_3.pdf">How Likely A Coalition of Voters Can Influence A Large Election?</a></td>
										  </tr>
										<tr>
											<td>05:20-05:40</td>
											<td>Paper Spotlight</td>
										 	 <td>Fan Yao, Chuanhao Li, Denis Nekipelov, Hongning Wang and Haifeng Xu</td>
										<td>Learning from a Learning User for Optimal Recommendations</td>
									    </tr>
										<tr>
											<td>05:40-06:00</td>
											<td>Paper Spotlight</td>
										 	 <td>Keegan Harris, Daniel Ngo, Logan Stapleton, Hoda Heidari and Z. Steven Wu</td>
										    <td><a href="papers/LSA-2022_paper_4.pdf">Strategic Instrumental Variable Regression: Recovering Causal Relationships From Strategic Responses</a></td>
										  </tr>
									</table>
									<h3>Invited Talks</h3>
									<p>
									<b>Speaker: </b> <a href="http://polaris.imag.fr/panayotis.mertikopoulos/">Panayotis Mertikopoulos</a>, French National Center for Scientific Research (CNRS) <br>
									<b>Title: </b> Limits and Limit Points of Game-Theoretic Learning <br>
									<b>Abstract: </b> Does learning from empirical observations in a game-theoretic setting converge to a Nash equilibrium? And, if so, at what rate? A well-known impossibility result in the field precludes the possibility of a "universally positive" answer - i.e., the existence a dynamical process which, based on player-specific information alone, converges to Nash equilibrium in all games. In view of this, we will instead examine the equilibrium convergence properties of a class of widely used no-regret learning processes which includes the exponential weights algorithm and the “follow the regularized leader” family of methods, their optimistic variants, extra-gradient schemes, and many others. In this general context, we establish a comprehensive equivalence between the stability of a Nash equilibrium and its support: a Nash equilibrium is locally stable and attracting if and only if it is strict (i.e., each equilibrium strategy has a unique best response). We will also discuss the robustness of this equivalence to different feedback models - from full information to bandit, payoff-based feedback - as well as the methods' rate of convergence in terms of the underlying regularizer and the type of feedback available to the players.<br>
									<b>Bio: </b> Panayotis Mertikopoulos is a principal researcher at the French National Center for Scientific Research (CNRS). Before joining CNRS, he received his undergraduate degree in physics from the University of Athens, his MSc and MPhil in mathematics from Brown University, and his PhD also from the University of Athens. He has since spent a year at École Polytechnique in France as a postdoctoral researcher, and has held visiting positions as an invited professor at the University of Rome, UC Berkeley, and EPFL. His research interests span the interface of game theory, learning and optimization, with a special view towards their applications to machine learning, operations research, and network theory. He is especially interested in the equilibrium convergence properties of multi-agent learning algorithms and dynamics, their rate of convergence (when they converge), and the type of off-equilibrium behavior that may arise (when they do not).
									</p>
									<p>
									<b>Speaker: </b><a href="https://cs.brown.edu/people/faculty/amy/">Amy Greenwald</a>, Brown University <br>
									TBA
									</p>
									
								</article>

						</div>
					</div>
				</div>

			<!-- Footer -->
				<div id="footer-wrapper">
					<footer id="footer" class="container">
						<div class="row">
							<div class="col-12">
								<div id="copyright">
									<ul class="menu">
										<li>&copy;  AAMAS 2022. All rights reserved</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
									</ul>
								</div>
							</div>
						</div>
					</footer>
				</div>

			</div>

		<!-- Scripts -->

			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.dropotron.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
